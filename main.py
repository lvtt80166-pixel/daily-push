import requests
import json
import re
from datetime import datetime

# ==================== ğŸ‘‡ é…ç½®åŒºåŸŸ ğŸ‘‡ ====================
# ä½ çš„é£ä¹¦ Webhook åœ°å€ (ä¿æŒä¸å˜)
WEBHOOK_URL = "https://open.feishu.cn/open-apis/bot/v2/hook/f241b8ab-434f-48f4-997c-5d8437a3f9e1"

# çº¯å‡€é˜…è¯»å‰ç¼€ (è¿™æ˜¯æŠŠç½‘é¡µè½¬æˆçº¯æ–‡å­—çš„é»‘ç§‘æŠ€)
# ç‚¹å‡»é“¾æ¥åï¼Œä¼šé€šè¿‡ Jina AI è‡ªåŠ¨æå–æ­£æ–‡ï¼Œä¸æ˜¾ç¤ºåŸç½‘é¡µå¹¿å‘Š
READ_API = "https://r.jina.ai/"
# ========================================================

def get_headers():
    """ä¼ªè£…æˆæ‰‹æœºæµè§ˆå™¨ (è·å–ç§»åŠ¨ç«¯æ•°æ®é€šå¸¸æ›´å…¨)"""
    return {
        'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 16_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 Mobile/15E148 Safari/604.1',
        'Accept': 'application/json, text/plain, */*'
    }

def clean_link(url):
    """å°†é“¾æ¥è½¬æ¢ä¸ºçº¯å‡€é˜…è¯»æ¨¡å¼"""
    return f"{READ_API}{url}"

# ========== 1. ç™¾åº¦çƒ­æœ (çˆ¬è™«) ==========
def scrape_baidu():
    print("ğŸ” æ­£åœ¨æŠ“å–ç™¾åº¦...")
    data = []
    try:
        url = "https://top.baidu.com/board?tab=realtime"
        # ç™¾åº¦æ¯”è¾ƒç‰¹æ®Šï¼Œéœ€è¦ç”¨ç”µè„‘ UA
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0 Safari/537.36'}
        resp = requests.get(url, headers=headers, timeout=10)
        content = resp.text
        # æ­£åˆ™æå–
        titles = re.findall(r'"word":"(.*?)",', content)
        # ç™¾åº¦çƒ­åº¦å€¼é€šå¸¸åœ¨ desc é™„è¿‘ï¼Œè¿™é‡Œç®€åŒ–ï¼Œç›´æ¥æŒ‰é¡ºåºï¼ˆç™¾åº¦é»˜è®¤å°±æ˜¯æŒ‰çƒ­åº¦æ’çš„ï¼‰
        for t in titles[:10]:
            if t:
                data.append({
                    "title": t,
                    "url": clean_link(f"https://www.baidu.com/s?wd={t}"),
                    "heat": "Top" # ç™¾åº¦ç½‘é¡µç‰ˆå¾ˆéš¾æ­£åˆ™å‡ºå‡†ç¡®çƒ­åº¦æ•°å­—
                })
        print(f"âœ… ç™¾åº¦: {len(data)} æ¡")
    except Exception as e:
        print(f"âŒ ç™¾åº¦å¤±è´¥: {e}")
    return data

# ========== 2. å¾®åšçƒ­æœ (çˆ¬è™«) ==========
def scrape_weibo():
    print("ğŸ” æ­£åœ¨æŠ“å–å¾®åš...")
    data = []
    try:
        url = "https://s.weibo.com/top/summary"
        headers = {'Cookie': 'SUB=1'} # å¾®åšå¿…å¡«
        resp = requests.get(url, headers=headers, timeout=10)
        html = resp.text
        # æ­£åˆ™æå–: href, æ ‡é¢˜, çƒ­åº¦
        # æ ¼å¼: <a href="/weibo?q=...">æ ‡é¢˜</a> ... <span>123456</span>
        pattern = re.compile(r'<a href="(/weibo\?q=[^"]+)" target="_blank">([^<]+)</a>.*?<span>(\d+)</span>', re.S)
        matches = pattern.findall(html)
        
        for m in matches[:10]:
            data.append({
                "title": m[1],
                "url": clean_link(f"https://s.weibo.com{m[0]}"),
                "heat": f"{int(m[2])/10000:.1f}w" # æ¢ç®—æˆä¸‡
            })
        print(f"âœ… å¾®åš: {len(data)} æ¡")
    except Exception as e:
        print(f"âŒ å¾®åšå¤±è´¥: {e}")
    return data

# ========== 3. çŸ¥ä¹çƒ­æ¦œ (API) ==========
def scrape_zhihu():
    print("ğŸ” æ­£åœ¨æŠ“å–çŸ¥ä¹...")
    data = []
    try:
        # çŸ¥ä¹å®˜æ–¹æ¥å£ (æ¯”ç½‘é¡µçˆ¬è™«ç¨³å®š)
        url = "https://api.zhihu.com/topstory/hot-list"
        resp = requests.get(url, headers=get_headers(), timeout=10)
        res_json = resp.json()
        
        items = res_json.get('data', [])
        for item in items[:10]:
            target = item.get('target', {})
            title = target.get('title')
            link = target.get('url', '').replace('api.zhihu.com/questions', 'www.zhihu.com/question')
            heat_val = item.get('detail_text', '').replace(' çƒ­åº¦', '')
            
            if title and link:
                data.append({
                    "title": title,
                    "url": clean_link(link),
                    "heat": heat_val
                })
        print(f"âœ… çŸ¥ä¹: {len(data)} æ¡")
    except Exception as e:
        print(f"âŒ çŸ¥ä¹å¤±è´¥: {e}")
    return data

# ========== 4. ä»Šæ—¥å¤´æ¡ (èšåˆAPI) ==========
def scrape_toutiao():
    print("ğŸ” æ­£åœ¨æŠ“å–å¤´æ¡...")
    data = []
    try:
        # å¤´æ¡åçˆ¬æœ€å˜æ€ï¼Œç›´æ¥æŠ“ç½‘é¡µå¿…æ­»ã€‚
        # è¿™é‡Œä½¿ç”¨ä¸€ä¸ªç¨³å®šçš„èšåˆæºï¼Œå¦‚æœè¿™ä¸ªæŒ‚äº†ï¼Œè„šæœ¬ä¸ä¼šå´©ï¼Œåªä¼šè·³è¿‡å¤´æ¡
        url = "https://api.oioweb.cn/api/common/toutiao/hotSearch"
        resp = requests.get(url, headers=get_headers(), timeout=15)
        res_json = resp.json()
        
        if res_json.get('code') == 200:
            items = res_json.get('result', [])
            for item in items[:10]:
                title = item.get('word')
                # å¤´æ¡æ²¡æœ‰ç›´æ¥é“¾æ¥ï¼Œé€šå¸¸æ˜¯æœç´¢é“¾æ¥
                link = f"https://so.toutiao.com/search?keyword={title}"
                heat = item.get('hot_value', 'Top')
                
                data.append({
                    "title": title,
                    "url": clean_link(link),
                    "heat": heat
                })
            print(f"âœ… å¤´æ¡: {len(data)} æ¡")
    except Exception as e:
        print(f"âŒ å¤´æ¡å¤±è´¥: {e}")
    return data

# ========== å‘é€é€»è¾‘ ==========
def send_feishu(wb_data, bd_data, zh_data, tt_data):
    # æ„å»ºå¡ç‰‡å†…å®¹
    today = datetime.now().strftime("%Y-%m-%d")
    
    # å®šä¹‰ä¸€ä¸ªå°å‡½æ•°æ¥ç”Ÿæˆæ¿å—
    def make_section(title, icon, data_list):
        if not data_list: return ""
        text = f"\n{icon} **{title}**\n"
        for i, item in enumerate(data_list):
            # æ ¼å¼: 1. æ ‡é¢˜ (çƒ­åº¦)
            # é“¾æ¥å·²ç»å…¨éƒ¨è¢«æ›¿æ¢ä¸º Jina Reader é“¾æ¥
            heat_str = f" ğŸ”¥{item['heat']}" if item.get('heat') else ""
            text += f"{i+1}. [{item['title']}]({item['url']}){heat_str}\n"
        return text

    content = f"ğŸ“… **{today} å…¨ç½‘çˆ†æ¬¾é€‰é¢˜è¡¨**\n> ç‚¹å‡»æ ‡é¢˜å¯ç›´æ¥æŸ¥çœ‹çº¯å‡€æ–‡å­—ç‰ˆ"
    content += make_section("å¾®åšçƒ­æœ", "ğŸ”´", wb_data)
    content += make_section("çŸ¥ä¹çƒ­æ¦œ", "ğŸ”µ", zh_data)
    content += make_section("ç™¾åº¦çƒ­æœ", "ğŸŸ¢", bd_data)
    content += make_section("ä»Šæ—¥å¤´æ¡", "ğŸŸ ", tt_data)

    headers = {'Content-Type': 'application/json'}
    payload = {
        "msg_type": "interactive",
        "card": {
            "header": {
                "template": "blue",
                "title": {"content": "ğŸ”¥ çˆ†æ¬¾é€‰é¢˜æŒ–æ˜æœº (çº¯å‡€é˜…è¯»ç‰ˆ)", "tag": "plain_text"}
            },
            "elements": [
                {"tag": "div", "text": {"content": content, "tag": "lark_md"}},
                {
                    "tag": "note", 
                    "elements": [{"content": "æç¤º: é“¾æ¥å·²é€šè¿‡ AI è½¬ä¸ºçº¯æ–‡æœ¬ï¼ŒåŠ è½½é€Ÿåº¦æå¿«", "tag": "plain_text"}]
                }
            ]
        }
    }
    
    try:
        requests.post(WEBHOOK_URL, headers=headers, data=json.dumps(payload))
        print("ğŸ‰ å‘é€æˆåŠŸï¼")
    except Exception as e:
        print(f"å‘é€é£ä¹¦å¤±è´¥: {e}")

def main():
    print("ğŸš€ ä»»åŠ¡å¯åŠ¨...")
    
    # å¹¶è¡ŒæŠ“å– (å…¶å®æ˜¯ä¸²è¡Œï¼Œä½†å¾ˆå¿«)
    wb = scrape_weibo()
    bd = scrape_baidu()
    zh = scrape_zhihu()
    tt = scrape_toutiao()
    
    # åªè¦æœ‰ä¸€ä¸ªæºæœ‰æ•°æ®ï¼Œå°±å‘é€
    if wb or bd or zh or tt:
        send_feishu(wb, bd, zh, tt)
    else:
        print("âš ï¸ å…¨å†›è¦†æ²¡ï¼Œæ‰€æœ‰æ¥å£éƒ½æ‹¿ä¸åˆ°æ•°æ®ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–IPã€‚")

if __name__ == "__main__":
    main()
